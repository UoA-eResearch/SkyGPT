{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from models import ConvLSTM, EncoderRNN\n",
    "import os\n",
    "import h5py\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tensorflow version\n",
    "print(\"pytorch version:\", torch.__version__)\n",
    "# check available gpu\n",
    "gpus =  torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "print(\"available gpus:\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "pardir = os.path.dirname(os.path.dirname(cwd))\n",
    "data_folder = os.path.join(pardir,'data')\n",
    "data_path = os.path.join(data_folder,'video_prediction_dataset.hdf5')\n",
    "model_name = 'ConvLSTM'\n",
    "output_folder = os.path.join(cwd,\"save\", model_name)\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "print(\"data_folder:\", data_folder)\n",
    "print(\"data_path:\", data_path)\n",
    "print(\"output_folder:\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate handler for the hdf5 data\n",
    "forecast_dataset = h5py.File(data_path, 'r')\n",
    "\n",
    "# show structure of the hdf5 data\n",
    "def get_all(name):\n",
    "    if name!=None:\n",
    "        print(forecast_dataset[name])\n",
    "    \n",
    "forecast_dataset.visit(get_all)\n",
    "\n",
    "forecast_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_path,'r') as f:\n",
    "    trainval = f['trainval']\n",
    "    images_log_train = trainval['images_log'][...][:,::2,:,:,:]\n",
    "    images_pred_train = trainval['images_pred'][...][:,::2,:,:,:]\n",
    "    \n",
    "    test = f['test']\n",
    "    images_log_test = test['images_log'][...][:,::2,:,:,:]\n",
    "    images_pred_test = test['images_pred'][...][:,::2,:,:,:]\n",
    "\n",
    "times_curr_train = np.load(os.path.join(data_folder,\"times_curr_trainval.npy\"),allow_pickle=True)\n",
    "times_curr_test = np.load(os.path.join(data_folder,\"times_curr_test.npy\"),allow_pickle=True)\n",
    "\n",
    "print('-'*50)\n",
    "print(\"times_curr_train.shape:\", times_curr_train.shape)\n",
    "print(\"images_log_train.shape:\", images_log_train.shape)\n",
    "print(\"images_pred_train.shape:\", images_pred_train.shape) \n",
    "print(\"times_curr_test.shape:\", times_curr_test.shape)\n",
    "print(\"images_log_test.shape:\", images_log_test.shape)\n",
    "print(\"images_pred_test.shape:\", images_pred_test.shape)\n",
    "print('-'*50)\n",
    "\n",
    "# get the input dimension for constructing the model\n",
    "num_log_frame = images_log_train.shape[1]\n",
    "img_side_len = images_log_train.shape[2]\n",
    "num_color_channel = images_log_train.shape[4]\n",
    "num_pred_frame = images_pred_train.shape[1]\n",
    "image_log_dim = [num_log_frame,img_side_len,img_side_len,num_color_channel]\n",
    "image_pred_dim = [num_pred_frame,img_side_len,img_side_len,num_color_channel]\n",
    "\n",
    "print(\"image side length:\", img_side_len)\n",
    "print(\"number of log frames:\", num_log_frame)\n",
    "print(\"number of pred frames:\", num_pred_frame)\n",
    "print(\"number of color channels:\", num_color_channel)\n",
    "print(\"context(log) image dimension:\", image_log_dim)\n",
    "print(\"future(pred) image dimension:\", image_pred_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SkyImageDataset(data.Dataset):\n",
    "    def __init__(self, data_set, transform=None):\n",
    "        self.data_set = data_set\n",
    "        self.transform = transform\n",
    "        self.length = self.data_set[0].shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        input_data = self.data_set[0][idx]\n",
    "        output_data = self.data_set[1][idx]\n",
    "        length = len(input_data)\n",
    "        input_data = input_data.transpose(0, 3, 1, 2)\n",
    "        output_data = output_data.transpose(0, 3, 1, 2)\n",
    "        \n",
    "        output_data = torch.from_numpy(output_data / 255.0).contiguous().float()\n",
    "        input_data = torch.from_numpy(input_data / 255.0).contiguous().float()\n",
    "\n",
    "        out = [idx,input_data,output_data]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "batch_size_train = 16\n",
    "batch_size_test = 64\n",
    "nepochs = 50\n",
    "print('nepochs:',nepochs)\n",
    "print_every = 1\n",
    "eval_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = SkyImageDataset([images_log_train, images_pred_train])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=data_set, batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "data_set = SkyImageDataset([images_log_test, images_pred_test])\n",
    "test_loader = torch.utils.data.DataLoader(dataset=data_set, batch_size=batch_size_test, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_on_batch(input_tensor, target_tensor, encoder, encoder_optimizer, criterion,teacher_forcing_ratio):                \n",
    "    encoder_optimizer.zero_grad()\n",
    "    input_length  = input_tensor.size(1)\n",
    "    target_length = target_tensor.size(1)\n",
    "    loss = 0\n",
    "    for ei in range(input_length-1): \n",
    "        output_image = encoder(input_tensor[:,ei,:,:,:], (ei==0) )\n",
    "        loss += criterion(output_image,input_tensor[:,ei+1,:,:,:])\n",
    "\n",
    "    decoder_input = input_tensor[:,-1,:,:,:] # first decoder input = last image of input sequence\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False \n",
    "    for di in range(target_length):\n",
    "        output_image = encoder(decoder_input)\n",
    "        target = target_tensor[:,di,:,:,:]\n",
    "        loss += criterion(output_image,target)\n",
    "        if use_teacher_forcing:\n",
    "            decoder_input = target # Teacher forcing    \n",
    "        else:\n",
    "            decoder_input = output_image\n",
    "\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def trainIters(encoder, nepochs, print_every=10,eval_every=10,name=''):\n",
    "    train_losses = []\n",
    "    best_mse = float('inf')\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(),lr=0.001)\n",
    "    scheduler_enc = ReduceLROnPlateau(encoder_optimizer, mode='min', patience=2,factor=0.1,verbose=True)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(0, nepochs):\n",
    "        t0 = time.time()\n",
    "        loss_epoch = 0\n",
    "        teacher_forcing_ratio = np.maximum(0 , 1 - epoch * 0.03) \n",
    "        \n",
    "        for i, out in enumerate(train_loader, 0):\n",
    "            input_tensor = out[1].to(device)\n",
    "            target_tensor = out[2].to(device)\n",
    "            loss = train_on_batch(input_tensor, target_tensor, encoder, encoder_optimizer, criterion, teacher_forcing_ratio)                                   \n",
    "            loss_epoch += loss\n",
    "                      \n",
    "        train_losses.append(loss_epoch)        \n",
    "        if (epoch+1) % print_every == 0:\n",
    "            print('-'*50)\n",
    "            print('epoch ',epoch,  ' loss ',loss_epoch, ' time epoch ',time.time()-t0)\n",
    "            print(\"saving model...\")\n",
    "            torch.save(encoder.state_dict(),'save/{0}/encoder.pth'.format(name)) \n",
    "            \n",
    "        if (epoch+1) % eval_every == 0:\n",
    "            mse_per_frame,mae_per_frame,mse_per_pixel,mae_per_pixel,_,_ = evaluate(encoder,test_loader) \n",
    "            scheduler_enc.step(mse_per_frame)\n",
    "             \n",
    "            \n",
    "    return train_losses\n",
    "\n",
    "def evaluate(encoder,loader):\n",
    "    print(\"validation start...\")\n",
    "    total_mse, total_mae = 0,0\n",
    "    t0 = time.time()\n",
    "    predictions = []\n",
    "    indices = []\n",
    "    num_val_samples = len(times_curr_test)\n",
    "    with torch.no_grad():\n",
    "        for i, out in enumerate(loader, 0):\n",
    "            indices.append(out[0])\n",
    "            input_tensor = out[1].to(device)\n",
    "            target_tensor = out[2].to(device)\n",
    "            input_length = input_tensor.size()[1]\n",
    "            target_length = target_tensor.size()[1]\n",
    "\n",
    "            for ei in range(input_length-1):\n",
    "                _  = encoder(input_tensor[:,ei,:,:,:], (ei==0))\n",
    "\n",
    "            decoder_input = input_tensor[:,-1,:,:,:] # first decoder input= last image of input sequence\n",
    "            prediction = []\n",
    "            \n",
    "            for di in range(target_length):\n",
    "                output_image = encoder(decoder_input, False)\n",
    "                decoder_input = output_image\n",
    "                prediction.append(output_image.cpu())\n",
    "            \n",
    "            input = input_tensor.cpu().numpy()\n",
    "            target = target_tensor.cpu().numpy()\n",
    "            prediction =  np.stack(prediction) # (8, batch_size, 3, 64, 64)\n",
    "            prediction = prediction.swapaxes(0,1)  # (batch_size, 8, 3, 64, 64)\n",
    "            \n",
    "            mse_batch = np.mean((prediction-target)**2, axis=1).sum()\n",
    "            mae_batch = np.mean(np.abs(prediction-target),  axis=1).sum() \n",
    "            total_mse += mse_batch\n",
    "            total_mae += mae_batch\n",
    "            \n",
    "            predictions.append(prediction)\n",
    "    \n",
    "    predictions =  np.concatenate(predictions,axis=0) # (batch_size, 8, 3, 64, 64)\n",
    "    total_mse_per_frame = total_mse/num_val_samples\n",
    "    total_mae_per_frame = total_mae/num_val_samples\n",
    "    total_mse_per_pixel = total_mse_per_frame/(img_side_len*img_side_len*num_color_channel)\n",
    "    total_mae_per_pixel = total_mae_per_frame/(img_side_len*img_side_len*num_color_channel)\n",
    "    \n",
    "    print('eval mse per frame:',total_mse_per_frame)\n",
    "    print('eval mae per frame:', total_mae_per_frame) \n",
    "    print('eval mse per pixel:',total_mse_per_pixel) \n",
    "    print('eval mae per pixel:', total_mae_per_pixel) \n",
    "    print('time:', time.time()-t0)        \n",
    "    \n",
    "    return total_mse_per_frame,  total_mae_per_frame, total_mse_per_pixel, total_mae_per_pixel, predictions, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convcell = ConvLSTM(input_shape=(64,64), input_dim=3, hidden_dims=[128,128,64], n_layers=3, kernel_size=(3,3), device=device) \n",
    "encoder = EncoderRNN(convcell, device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "   \n",
    "print('convcell ' , count_parameters(convcell) ) \n",
    "print('encoder ' , count_parameters(encoder) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loss = trainIters(encoder,nepochs,print_every=print_every,eval_every=eval_every,name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Predicted Images from Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('save/{0}/encoder.pth'.format(model_name)))\n",
    "encoder.eval()\n",
    "mse_per_frame, mae_per_frame, mse_per_pixel, mae_per_pixel, predictions, indices = evaluate(encoder,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "predictions = predictions.transpose((0,1,3,4,2))\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('save/{0}/predicted_images.npy'.format(model_name), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Some Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "select_num_samples = 30\n",
    "select_idx = random.sample(np.arange(len(predictions)).tolist(),select_num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(select_num_samples):\n",
    "    print(\"-\"*50,\"sample \",str(i+1), \"-\"*50)\n",
    "    f, ax = plt.subplots(2,8)\n",
    "    f.set_size_inches(24,6)\n",
    "    ax[0,0].imshow(images_log_test[select_idx[i]][0][:,:,::-1])\n",
    "    ax[0,0].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=15))\n",
    "    ax[0,1].imshow(images_log_test[select_idx[i]][2][:,:,::-1])\n",
    "    ax[0,1].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=11))\n",
    "    ax[0,2].imshow(images_log_test[select_idx[i]][4][:,:,::-1])\n",
    "    ax[0,2].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=7))\n",
    "    ax[0,3].imshow(images_log_test[select_idx[i]][7][:,:,::-1])\n",
    "    ax[0,3].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=1))\n",
    "    ax[0,4].imshow(images_pred_test[select_idx[i]][0][:,:,::-1])\n",
    "    ax[0,4].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=1))\n",
    "    ax[0,5].imshow(images_pred_test[select_idx[i]][2][:,:,::-1])\n",
    "    ax[0,5].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=5))\n",
    "    ax[0,6].imshow(images_pred_test[select_idx[i]][4][:,:,::-1])\n",
    "    ax[0,6].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=9))\n",
    "    ax[0,7].imshow(images_pred_test[select_idx[i]][7][:,:,::-1])\n",
    "    ax[0,7].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=15))\n",
    "    \n",
    "    ax[1,4].imshow(predictions[select_idx[i]][0][:,:,::-1])\n",
    "    ax[1,5].imshow(predictions[select_idx[i]][2][:,:,::-1])\n",
    "    ax[1,6].imshow(predictions[select_idx[i]][4][:,:,::-1])\n",
    "    ax[1,7].imshow(predictions[select_idx[i]][7][:,:,::-1])\n",
    "    \n",
    "    ax[0,0].axis('off')\n",
    "    ax[0,1].axis('off')\n",
    "    ax[0,2].axis('off')\n",
    "    ax[0,3].axis('off')\n",
    "    ax[0,4].axis('off')\n",
    "    ax[0,5].axis('off')\n",
    "    ax[0,6].axis('off')\n",
    "    ax[0,7].axis('off')\n",
    "    ax[1,0].axis('off')\n",
    "    ax[1,1].axis('off')\n",
    "    ax[1,2].axis('off')\n",
    "    ax[1,3].axis('off')\n",
    "    ax[1,4].axis('off')\n",
    "    ax[1,5].axis('off')\n",
    "    ax[1,6].axis('off')\n",
    "    ax[1,7].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
