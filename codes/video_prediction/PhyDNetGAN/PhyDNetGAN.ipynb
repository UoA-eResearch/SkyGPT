{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN with least square adversarial loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from models_v2 import ConvLSTM, PhyCell, EncoderRNN\n",
    "from constrain_moments import K2M\n",
    "import os\n",
    "import h5py\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create the training, validation set for PhyDNet model testing on Sky image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# day block shuffling of the time stamps, and return shuffled indices\n",
    "def day_block_shuffle(times_trainval):\n",
    "    \n",
    "    # Only keep the date of each time point\n",
    "    dates_trainval = np.zeros_like(times_trainval, dtype=datetime.date)\n",
    "    for i in range(len(times_trainval)):\n",
    "        dates_trainval[i] = times_trainval[i].date()\n",
    "\n",
    "    # Chop the indices into blocks, so that each block contains the indices of the same day\n",
    "    unique_dates = np.unique(dates_trainval)\n",
    "    blocks = []\n",
    "    for i in range(len(unique_dates)):\n",
    "        blocks.append(np.where(dates_trainval == unique_dates[i])[0])\n",
    "\n",
    "    # shuffle the blocks, and chain it back together\n",
    "    np.random.seed(1)\n",
    "    np.random.shuffle(blocks)\n",
    "    shuffled_indices = np.asarray(list(itertools.chain.from_iterable(blocks)))\n",
    "\n",
    "    return shuffled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spliting the dayblock shuffled indices into training and validation\n",
    "def trainval_split(split_data, split_ratio):\n",
    "    '''\n",
    "    input:\n",
    "    split_data: the dayblock shuffled indices to be splitted\n",
    "    fold_index: the ith fold chosen as the validation, used for generating the seed for random shuffling\n",
    "    num_fold: N-fold cross validation\n",
    "    output:\n",
    "    data_train: the train data indices\n",
    "    data_val: the validation data indices\n",
    "    '''\n",
    "    # randomly divides into a training set and a validation set\n",
    "    num_samples = len(split_data[0])\n",
    "    indices = np.arange(num_samples)\n",
    "\n",
    "    # finding training and validation indices\n",
    "    val_mask = np.zeros(len(indices), dtype=bool)\n",
    "    val_mask[:int(split_ratio * num_samples)] = True\n",
    "    val_indices = indices[val_mask]\n",
    "    train_indices = indices[np.logical_not(val_mask)]\n",
    "\n",
    "    # shuffle indices\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(val_indices)\n",
    "    \n",
    "    # Initialize the training and validation data set list\n",
    "    data_train = []\n",
    "    data_val = []\n",
    "    # obtain training and validation data\n",
    "    for one_data in split_data:\n",
    "        one_train, one_val = one_data[train_indices], one_data[val_indices]\n",
    "        data_train.append(one_train)\n",
    "        data_val.append(one_val)\n",
    "\n",
    "    return data_train,data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "pardir = os.path.dirname(os.path.dirname(cwd))\n",
    "data_folder = os.path.join(pardir,'data')\n",
    "data_path = os.path.join(data_folder,'video_prediction_dataset.hdf5')\n",
    "print(\"data_folder:\", data_folder)\n",
    "print(\"data_path:\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(data_path,'r') as f:\n",
    "    trainval = f['trainval']\n",
    "    images_log_train = trainval['images_log'][...][:,::2,:,:,:]\n",
    "    images_pred_train = trainval['images_pred'][...][:,::2,:,:,:]\n",
    "    \n",
    "    test = f['test']\n",
    "    images_log_test = test['images_log'][...][:,::2,:,:,:]\n",
    "    images_pred_test = test['images_pred'][...][:,::2,:,:,:]\n",
    "\n",
    "times_curr_train = np.load(os.path.join(data_folder,\"times_curr_trainval.npy\"),allow_pickle=True)\n",
    "times_curr_test = np.load(os.path.join(data_folder,\"times_curr_test.npy\"),allow_pickle=True)\n",
    "print('-'*50)\n",
    "print(\"times_curr_train.shape:\", times_curr_train.shape)\n",
    "print(\"images_log_train.shape:\", images_log_train.shape)\n",
    "print(\"images_pred_train.shape:\", images_pred_train.shape) \n",
    "print(\"times_curr_test.shape:\", times_curr_test.shape)\n",
    "print(\"images_log_test.shape:\", images_log_test.shape)\n",
    "print(\"images_pred_test.shape:\", images_pred_test.shape)\n",
    "print('-'*50)\n",
    "# get the input dimension for constructing the model\n",
    "num_log_frame = images_log_train.shape[1]\n",
    "img_side_len = images_log_train.shape[2]\n",
    "num_color_channel = images_log_train.shape[4]\n",
    "num_pred_frame = images_pred_train.shape[1]\n",
    "image_log_dim = [num_log_frame,img_side_len,img_side_len,num_color_channel]\n",
    "image_pred_dim = [num_pred_frame,img_side_len,img_side_len,num_color_channel]\n",
    "\n",
    "print(\"image side length:\", img_side_len)\n",
    "print(\"number of log frames:\", num_log_frame)\n",
    "print(\"number of pred frames:\", num_pred_frame)\n",
    "print(\"number of color channels:\", num_color_channel)\n",
    "print(\"context(log) image dimension:\", image_log_dim)\n",
    "print(\"future(pred) image dimension:\", image_pred_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_path,'r') as f:\n",
    "    \n",
    "    test = f['test']\n",
    "    images_log_test = test['images_log'][...][:,::2,:,:,:]\n",
    "    images_pred_test = test['images_pred'][...][:,::2,:,:,:]\n",
    "\n",
    "times_curr_test = np.load(os.path.join(data_folder,\"times_curr_test.npy\"),allow_pickle=True)\n",
    "print(\"times_curr_test.shape:\", times_curr_test.shape)\n",
    "print(\"images_log_test.shape:\", images_log_test.shape)\n",
    "print(\"images_pred_test.shape:\", images_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input dimension for constructing the model\n",
    "num_log_frame = images_log_test.shape[1]\n",
    "img_side_len = images_log_test.shape[2]\n",
    "num_color_channel = images_log_test.shape[4]\n",
    "num_pred_frame = images_pred_test.shape[1]\n",
    "image_log_dim = [num_log_frame,img_side_len,img_side_len,num_color_channel]\n",
    "image_pred_dim = [num_pred_frame,img_side_len,img_side_len,num_color_channel]\n",
    "\n",
    "print(\"image side length:\", img_side_len)\n",
    "print(\"number of log frames:\", num_log_frame)\n",
    "print(\"number of pred frames:\", num_pred_frame)\n",
    "print(\"number of color channels:\", num_color_channel)\n",
    "print(\"context(log) image dimension:\", image_log_dim)\n",
    "print(\"future(pred) image dimension:\", image_pred_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SkyImageDataset(data.Dataset):\n",
    "    def __init__(self, data_set, transform=None):\n",
    "        self.data_set = data_set\n",
    "        self.transform = transform\n",
    "        self.length = self.data_set[0].shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        input_data = self.data_set[0][idx]\n",
    "        output_data = self.data_set[1][idx]\n",
    "        length = len(input_data)\n",
    "        input_data = input_data.transpose(0, 3, 1, 2)\n",
    "        output_data = output_data.transpose(0, 3, 1, 2)\n",
    "        \n",
    "        output_data = torch.from_numpy(output_data / 255.0).contiguous().float()\n",
    "        input_data = torch.from_numpy(input_data / 255.0).contiguous().float()\n",
    "        # print()\n",
    "        #print(input.size())\n",
    "        #print(output.size())\n",
    "\n",
    "        out = [idx,input_data,output_data]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 16\n",
    "\n",
    "# Frame discriminator \n",
    "class Discr_frame(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discr_frame, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, ndf * 16, 4, 1, 0, bias=False),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(ndf * 16, 1)\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cwd = os.getcwd()\n",
    "data_folder = os.path.join(cwd,\"data\") \n",
    "batch_size = 16\n",
    "nepochs = 50\n",
    "print_every = 1\n",
    "eval_every = 5\n",
    "plot_every = 1*eval_every\n",
    "save_model_every = 1\n",
    "save_name = 'PhyDNetGAN'\n",
    "if not os.path.isdir('save/{}'.format(save_name)):\n",
    "    os.mkdir('save/{}'.format(save_name))\n",
    "lamda = 0.01 # weight for generator adversarial loss\n",
    "training_discriminator_every=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = SkyImageDataset([images_log_train, images_pred_train])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=data_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_set = SkyImageDataset([images_log_test, images_pred_test])\n",
    "test_loader = torch.utils.data.DataLoader(dataset=data_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraints = torch.zeros((49,7,7)).to(device)\n",
    "ind = 0\n",
    "for i in range(0,7):\n",
    "    for j in range(0,7):\n",
    "        constraints[ind,i,j] = 1\n",
    "        ind +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_gen_images(predictions,times_curr,images_log,images_pred,select_idx):\n",
    "    predictions = predictions.transpose((0,1,3,4,2))\n",
    "    for i in range(len(select_idx)):\n",
    "        #print(\"-\"*50,\"sample \",str(i+1), \"-\"*50)\n",
    "        f, ax = plt.subplots(2,8)\n",
    "        f.subplots_adjust(wspace=0, hspace=0)\n",
    "        f.set_size_inches(24,6)\n",
    "        ax[0,0].imshow(images_log[select_idx[i]][0][:,:,::-1])\n",
    "        ax[0,0].set_title(times_curr[select_idx[i]]-datetime.timedelta(minutes=14))\n",
    "        ax[0,1].imshow(images_log[select_idx[i]][2][:,:,::-1])\n",
    "        ax[0,1].set_title(times_curr[select_idx[i]]-datetime.timedelta(minutes=10))\n",
    "        ax[0,2].imshow(images_log[select_idx[i]][4][:,:,::-1])\n",
    "        ax[0,2].set_title(times_curr[select_idx[i]]-datetime.timedelta(minutes=6))\n",
    "        ax[0,3].imshow(images_log[select_idx[i]][7][:,:,::-1])\n",
    "        ax[0,3].set_title(times_curr[select_idx[i]])\n",
    "        ax[0,4].imshow(images_pred[select_idx[i]][0][:,:,::-1])\n",
    "        ax[0,4].set_title(times_curr[select_idx[i]]+datetime.timedelta(minutes=1))\n",
    "        ax[0,5].imshow(images_pred[select_idx[i]][2][:,:,::-1])\n",
    "        ax[0,5].set_title(times_curr[select_idx[i]]+datetime.timedelta(minutes=5))\n",
    "        ax[0,6].imshow(images_pred[select_idx[i]][4][:,:,::-1])\n",
    "        ax[0,6].set_title(times_curr[select_idx[i]]+datetime.timedelta(minutes=9))\n",
    "        ax[0,7].imshow(images_pred[select_idx[i]][7][:,:,::-1])\n",
    "        ax[0,7].set_title(times_curr[select_idx[i]]+datetime.timedelta(minutes=15))\n",
    "\n",
    "        ax[1,4].imshow(predictions[select_idx[i]][0][:,:,::-1])\n",
    "        ax[1,5].imshow(predictions[select_idx[i]][2][:,:,::-1])\n",
    "        ax[1,6].imshow(predictions[select_idx[i]][4][:,:,::-1])\n",
    "        ax[1,7].imshow(predictions[select_idx[i]][7][:,:,::-1])\n",
    "\n",
    "        ax[0,0].axis('off')\n",
    "        ax[0,1].axis('off')\n",
    "        ax[0,2].axis('off')\n",
    "        ax[0,3].axis('off')\n",
    "        ax[0,4].axis('off')\n",
    "        ax[0,5].axis('off')\n",
    "        ax[0,6].axis('off')\n",
    "        ax[0,7].axis('off')\n",
    "        ax[1,0].axis('off')\n",
    "        ax[1,1].axis('off')\n",
    "        ax[1,2].axis('off')\n",
    "        ax[1,3].axis('off')\n",
    "        ax[1,4].axis('off')\n",
    "        ax[1,5].axis('off')\n",
    "        ax[1,6].axis('off')\n",
    "        ax[1,7].axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampling_step_1 = 15\n",
    "sampling_step_2 = 30\n",
    "r_exp_alpha = 2.5\n",
    "\n",
    "def reserve_schedule_sampling_exp(epoch, log_length):\n",
    "    real_input_flag_encoder = np.zeros(log_length, dtype=bool)\n",
    "    if epoch < sampling_step_1:\n",
    "        r_eta = 0.5\n",
    "    elif epoch < sampling_step_2:\n",
    "        r_eta = 1.0 - 0.5 * math.exp(-float(epoch - sampling_step_1) / r_exp_alpha)\n",
    "    else:\n",
    "        r_eta = 1.0\n",
    "    for i in range(log_length):\n",
    "        real_input_flag_encoder[i] = True if random.random() < r_eta else False\n",
    "    return r_eta, real_input_flag_encoder\n",
    "\n",
    "def schedule_sampling(epoch,pred_length):\n",
    "    real_input_flag_decoder = np.zeros(pred_length, dtype=bool)\n",
    "    if epoch < sampling_step_1:\n",
    "        eta = 0.5\n",
    "    elif epoch < sampling_step_2:\n",
    "        eta = 0.5 - (0.5 / (sampling_step_2 - sampling_step_1)) * (epoch - sampling_step_1)\n",
    "    else:\n",
    "        eta = 0\n",
    "    for i in range(pred_length):\n",
    "        real_input_flag_decoder[i] = True if random.random() < eta else False\n",
    "    return eta, real_input_flag_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_eta = np.zeros(nepochs)\n",
    "eta = np.zeros(nepochs)\n",
    "for epoch in range(nepochs):\n",
    "    r_eta[epoch],real_input_flag_encoder = reserve_schedule_sampling_exp(epoch,num_log_frame)\n",
    "    eta[epoch],real_input_flag_decoder = schedule_sampling(epoch,num_pred_frame)\n",
    "plt.plot(range(nepochs),r_eta,label='r_eta')\n",
    "plt.plot(range(nepochs),eta,label='eta')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_on_batch(epoch, input_tensor, target_tensor, encoder, encoder_optimizer, criterion_mae, criterion_mse, discr_frame, discr_frame_optimizer):                \n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    \n",
    "    # input_tensor : torch.Size([batch_size, input_length, channels, cols, rows])\n",
    "    curr_batch_size = input_tensor.size(0)    \n",
    "    input_length  = input_tensor.size(1)\n",
    "    target_length = target_tensor.size(1)\n",
    "    loss = 0\n",
    "    encoder_frame_ad_loss = 0\n",
    "    real_label = torch.full((curr_batch_size,), 1, dtype=torch.float, device=device)\n",
    "    fake_label = torch.full((curr_batch_size,), 1, dtype=torch.float, device=device)\n",
    "    discr_frame_loss = 0\n",
    "    r_eta,real_input_flag_encoder = reserve_schedule_sampling_exp(epoch,input_length)\n",
    "    eta,real_input_flag_decoder = schedule_sampling(epoch,target_length)\n",
    "    \n",
    "    encoder_input = input_tensor[:,0,:,:,:]\n",
    "    for ei in range(input_length-1): \n",
    "        encoder_output, encoder_hidden, encoder_output_image,_,_ = encoder(encoder_input, (ei==0))\n",
    "        encoder_target = input_tensor[:,ei+1,:,:,:]\n",
    "        loss += criterion_mae(encoder_output_image,encoder_target)\n",
    "        \n",
    "        if real_input_flag_encoder[ei]:\n",
    "            encoder_input = encoder_target # Teacher forcing    \n",
    "        else:\n",
    "            encoder_input = encoder_output_image\n",
    "    \n",
    "    if real_input_flag_encoder[-1]:        \n",
    "        decoder_input = input_tensor[:,-1,:,:,:] \n",
    "    else:\n",
    "        decoder_input = encoder_output_image # first decoder input = last image of input sequence\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, output_image,_,_ = encoder(decoder_input)\n",
    "        target = target_tensor[:,di,:,:,:]\n",
    "        loss += criterion_mae(output_image,target)\n",
    "        if (epoch+1)%training_discriminator_every==0:\n",
    "            discr_frame_out_fake = discr_frame(output_image).view(-1)\n",
    "            encoder_frame_ad_loss += 0.5 * torch.mean((discr_frame_out_fake - 1)**2)\n",
    "        \n",
    "        if real_input_flag_decoder[di]:\n",
    "            decoder_input = target # Teacher forcing    \n",
    "        else:\n",
    "            decoder_input = output_image\n",
    "    \n",
    "    if (epoch+1)%training_discriminator_every==0:\n",
    "        loss += lamda*encoder_frame_ad_loss\n",
    "    \n",
    "    # Moment regularization  # encoder.phycell.cell_list[0].F.conv1.weight # size (nb_filters,in_channels,7,7)\n",
    "    k2m = K2M([7,7]).to(device)\n",
    "    for b in range(0,encoder.phycell.cell_list[0].input_dim):\n",
    "        filters = encoder.phycell.cell_list[0].F.conv1.weight[:,b,:,:] # (nb_filters,7,7)     \n",
    "        m = k2m(filters.double()) \n",
    "        m  = m.float()   \n",
    "        loss += criterion_mse(m, constraints) # constrains is a precomputed matrix   \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    \n",
    "    if (epoch+1)%training_discriminator_every==0:\n",
    "        discr_frame_optimizer.zero_grad()\n",
    "        if real_input_flag_encoder[-1]:        \n",
    "            decoder_input = input_tensor[:,-1,:,:,:] \n",
    "        else:\n",
    "            decoder_input = encoder_output_image # first decoder input = last image of input sequence\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, output_image,_,_ = encoder(decoder_input)\n",
    "            target = target_tensor[:,di,:,:,:]\n",
    "            discr_frame_out_real = discr_frame(target).view(-1)\n",
    "            discr_frame_out_fake = discr_frame(output_image.detach()).view(-1)\n",
    "            discr_frame_loss += 0.5 * (torch.mean((discr_frame_out_real - 1)**2) + torch.mean(discr_frame_out_fake**2))\n",
    "\n",
    "            if real_input_flag_decoder[di]:\n",
    "                decoder_input = target # Teacher forcing    \n",
    "            else:\n",
    "                decoder_input = output_image\n",
    "\n",
    "        discr_frame_loss.backward()\n",
    "        discr_frame_optimizer.step()\n",
    "        \n",
    "        return discr_frame_loss.item()/target_length, encoder_frame_ad_loss.item()/target_length, loss.item() / target_length\n",
    "    \n",
    "    else:\n",
    "        return discr_frame_loss/target_length, encoder_frame_ad_loss/target_length, loss.item() / target_length\n",
    "\n",
    "def trainIters(encoder, discr_frame, nepochs, print_every=10,eval_every=10,name=''):\n",
    "    encoder_total_train_losses = []\n",
    "    encoder_ad_train_losses = []\n",
    "    discr_train_losses = []\n",
    "    best_mse = float('inf')\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(),lr=0.001,betas=(0.5,0.99))\n",
    "    discr_frame_optimizer = torch.optim.Adam(discr_frame.parameters(),lr=0.0002,betas=(0.5,0.99))\n",
    "    scheduler_enc = ReduceLROnPlateau(encoder_optimizer, mode='min', patience=5, factor=0.1, verbose=True)\n",
    "    scheduler_discr = ReduceLROnPlateau(discr_frame_optimizer, mode='min', patience=5, factor=0.1, verbose=True)\n",
    "    criterion_mae = nn.L1Loss()\n",
    "    criterion_mse = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(0, nepochs):\n",
    "        t0 = time.time()\n",
    "        encoder_total_loss_epoch = 0\n",
    "        discr_loss_epoch = 0\n",
    "        encoder_ad_loss_epoch = 0\n",
    "        \n",
    "        for i, out in enumerate(train_loader, 0):\n",
    "            input_tensor = out[1].to(device)\n",
    "            target_tensor = out[2].to(device)\n",
    "            discr_frame_loss, encoder_frame_ad_loss, loss = train_on_batch(epoch, input_tensor, target_tensor, encoder, encoder_optimizer, criterion_mae, criterion_mse, discr_frame, discr_frame_optimizer)                                   \n",
    "            encoder_total_loss_epoch += loss\n",
    "            discr_loss_epoch += discr_frame_loss\n",
    "            encoder_ad_loss_epoch += encoder_frame_ad_loss\n",
    "        \n",
    "        encoder_total_train_losses.append(encoder_total_loss_epoch)     \n",
    "        encoder_ad_train_losses.append(encoder_ad_loss_epoch)\n",
    "        discr_train_losses.append(discr_loss_epoch)\n",
    "        \n",
    "        \n",
    "        if (epoch+1) % print_every == 0:\n",
    "            print('training epoch {0}/{1}'.format(epoch+1,nepochs))\n",
    "            print('encoder total loss:{0:.3f}'.format(encoder_total_loss_epoch))\n",
    "            print('time epoch:{0:.3f}s'.format(time.time()-t0))\n",
    "            \n",
    "        if (epoch+1) % save_model_every == 0:\n",
    "            print('saving the model...')\n",
    "            torch.save(encoder.state_dict(),'save/{0}/encoder.pth'.format(name))\n",
    "            torch.save(discr_frame.state_dict(),'save/{0}/discriminator.pth'.format(name))\n",
    "            \n",
    "        if (epoch+1) % training_discriminator_every == 0:  \n",
    "            print('encoder adversarial loss:{0:.3f}'.format(encoder_ad_loss_epoch))\n",
    "            print('discriminator loss:{0:.3f}'.format(discr_loss_epoch)) \n",
    "            f,ax=plt.subplots()\n",
    "            ax.plot(range(len(encoder_ad_train_losses)),encoder_ad_train_losses,label=\"gen_loss\")\n",
    "            ax.plot(range(len(discr_train_losses)),discr_train_losses,label='disc_loss')\n",
    "            ax.set_xlabel('epoch')\n",
    "            ax.set_ylabel('loss')\n",
    "            ax.legend()\n",
    "            f.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        if (epoch+1) % eval_every == 0:\n",
    "            mse,mae,predictions,_ = evaluate(encoder,test_loader)\n",
    "            scheduler_enc.step(mae)\n",
    "            scheduler_discr.step(mae)\n",
    "        \n",
    "        if (epoch+1) % plot_every == 0:\n",
    "            select_idx = [3445]\n",
    "            plot_gen_images(predictions,times_curr_test,images_log_test,images_pred_test,select_idx)\n",
    "        \n",
    "    return encoder_total_train_losses,encoder_ad_train_losses,discr_train_losses\n",
    "\n",
    "def evaluate(encoder,loader):\n",
    "    total_mse, total_mae = 0,0\n",
    "    t0 = time.time()\n",
    "    predictions = []\n",
    "    indices = []\n",
    "    with torch.no_grad():\n",
    "        for i, out in enumerate(loader, 0):\n",
    "            indices.append(out[0])\n",
    "            input_tensor = out[1].to(device)\n",
    "            target_tensor = out[2].to(device)\n",
    "            input_length = input_tensor.size()[1]\n",
    "            target_length = target_tensor.size()[1]\n",
    "\n",
    "            for ei in range(input_length-1):\n",
    "                encoder_output, encoder_hidden, _,_,_  = encoder(input_tensor[:,ei,:,:,:], (ei==0))\n",
    "\n",
    "            decoder_input = input_tensor[:,-1,:,:,:] # first decoder input= last image of input sequence\n",
    "            prediction = []\n",
    "            \n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, output_image,_,_ = encoder(decoder_input, False, False)\n",
    "                decoder_input = output_image\n",
    "                prediction.append(output_image.cpu())\n",
    "            \n",
    "            input = input_tensor.cpu().numpy()\n",
    "            target = target_tensor.cpu().numpy()\n",
    "            prediction =  np.stack(prediction) # (8, batch_size, 3, 64, 64)\n",
    "            prediction = prediction.swapaxes(0,1)  # (batch_size, 8, 3, 64, 64)\n",
    "            \n",
    "            \n",
    "            mse_batch = np.mean((prediction-target)**2 , axis=1).sum()\n",
    "            mae_batch = np.mean(np.abs(prediction-target) ,  axis=1).sum() \n",
    "            total_mse += mse_batch\n",
    "            total_mae += mae_batch\n",
    "            \n",
    "            predictions.append(prediction)\n",
    "    \n",
    "    predictions =  np.concatenate(predictions,axis=0) # (10, batch_size, 1, 64, 64)\n",
    "    print(\"validation...\")    \n",
    "    print('mse per frame:{0:.3f}'.format(total_mse/len(times_curr_test)))  \n",
    "    print('mae per frame:{0:.3f}'.format(total_mae/len(times_curr_test)))\n",
    "    print('mse per pixel:{0:.3f}'.format(total_mse/len(times_curr_test)/(img_side_len*img_side_len*num_color_channel)))  \n",
    "    print('mae per pixel:{0:.3f}'.format(total_mae/len(times_curr_test)/(img_side_len*img_side_len*num_color_channel)))\n",
    "    print('time:{0:.3f}s'.format(time.time()-t0))\n",
    "    print('-'*40)\n",
    "    return total_mse/len(times_curr_test),  total_mae/len(times_curr_test), predictions, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phycell  =  PhyCell(input_shape=(16,16), input_dim=64, F_hidden_dims=[49], n_layers=1, kernel_size=(7,7), device=device) \n",
    "convcell =  ConvLSTM(input_shape=(16,16), input_dim=64, hidden_dims=[128,128,64], n_layers=3, kernel_size=(3,3), device=device)   \n",
    "encoder  = EncoderRNN(phycell, convcell, device)\n",
    "discriminator_frame = Discr_frame().to(device)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "   \n",
    "print('phycell ' , count_parameters(phycell))    \n",
    "print('convcell ' , count_parameters(convcell)) \n",
    "print('encoder ' , count_parameters(encoder)) \n",
    "print('discriminator_frame ', count_parameters(discriminator_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_total_train_losses,encoder_ad_train_losses,discr_train_losses = trainIters(encoder,discriminator_frame,nepochs,print_every=print_every,eval_every=eval_every,name=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Predicted Images from Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = SkyImageDataset([images_log_test, images_pred_test])\n",
    "test_loader = torch.utils.data.DataLoader(dataset=data_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('save/{0}/encoder.pth'.format(save_name)))\n",
    "encoder.eval()\n",
    "mse, mae, predictions, indices = evaluate(encoder,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "predictions = predictions.transpose((0,1,3,4,2))\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('save/{0}/predicted_images.npy'.format(save_name), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiz Some Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "select_num_samples = 30\n",
    "select_idx = random.sample(np.arange(len(times_curr_test)).tolist(),select_num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(select_num_samples):\n",
    "    print(\"-\"*50,\"sample \",str(i+1), \"-\"*50)\n",
    "    f, ax = plt.subplots(2,8)\n",
    "    f.set_size_inches(24,6)\n",
    "    ax[0,0].imshow(images_log_test[select_idx[i]][0][:,:,::-1])\n",
    "    ax[0,0].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=15))\n",
    "    ax[0,1].imshow(images_log_test[select_idx[i]][2][:,:,::-1])\n",
    "    ax[0,1].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=11))\n",
    "    ax[0,2].imshow(images_log_test[select_idx[i]][4][:,:,::-1])\n",
    "    ax[0,2].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=7))\n",
    "    ax[0,3].imshow(images_log_test[select_idx[i]][7][:,:,::-1])\n",
    "    ax[0,3].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=1))\n",
    "    ax[0,4].imshow(images_pred_test[select_idx[i]][0][:,:,::-1])\n",
    "    ax[0,4].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=1))\n",
    "    ax[0,5].imshow(images_pred_test[select_idx[i]][2][:,:,::-1])\n",
    "    ax[0,5].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=5))\n",
    "    ax[0,6].imshow(images_pred_test[select_idx[i]][4][:,:,::-1])\n",
    "    ax[0,6].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=9))\n",
    "    ax[0,7].imshow(images_pred_test[select_idx[i]][7][:,:,::-1])\n",
    "    ax[0,7].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=15))\n",
    "    \n",
    "    ax[1,4].imshow(predictions[select_idx[i]][0][:,:,::-1])\n",
    "    ax[1,5].imshow(predictions[select_idx[i]][2][:,:,::-1])\n",
    "    ax[1,6].imshow(predictions[select_idx[i]][4][:,:,::-1])\n",
    "    ax[1,7].imshow(predictions[select_idx[i]][7][:,:,::-1])\n",
    "    \n",
    "    ax[0,0].axis('off')\n",
    "    ax[0,1].axis('off')\n",
    "    ax[0,2].axis('off')\n",
    "    ax[0,3].axis('off')\n",
    "    ax[0,4].axis('off')\n",
    "    ax[0,5].axis('off')\n",
    "    ax[0,6].axis('off')\n",
    "    ax[0,7].axis('off')\n",
    "    ax[1,0].axis('off')\n",
    "    ax[1,1].axis('off')\n",
    "    ax[1,2].axis('off')\n",
    "    ax[1,3].axis('off')\n",
    "    ax[1,4].axis('off')\n",
    "    ax[1,5].axis('off')\n",
    "    ax[1,6].axis('off')\n",
    "    ax[1,7].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
